<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Monstx's Blog</title>
        <link>https://blog.monsterx.cn/</link>
        <description>Monsterx CN - 学生 / 前端 / 电气</description>
        <lastBuildDate>Sun, 16 Aug 2020 11:17:29 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Gridsome Feed Plugin</generator>
        <atom:link href="https://blog.monsterx.cn/feed.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[New Start]]></title>
            <link>https://blog.monsterx.cn/life/new-start-with-gridsome/</link>
            <guid>https://blog.monsterx.cn/life/new-start-with-gridsome/</guid>
            <pubDate>Sat, 15 Aug 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>在这普通的一天，我穿着普通的鞋，很普通地呆在这普通的家，掏出普通的耳机，找点普通的感觉，来一首我最爱的普通音乐，踩着普通的鼓点，世界随着我旋转，这让我普通地单曲循环，跟着普通的节奏，手腕普通地抖动，这普通的一切，都变得不同……</p>
<!--more-->

<p>博客稳定两周年之际，我正式从动态博客迁移至静态博客，如你所见这个博客正由 <a href="https://gridsome.org">Gridsome</a> 驱动着。“Gridsome 是一个免费、开源、基于 Vue.js 构建的框架，用 Gridsome 创建的网站和应用程序具有天然的速度优势”，官网如是说，这确实是我选择她的一个理由，另外一个理由是身边用 <a href="https://hexo.io">Hexo</a> 的人似乎太多了，我想玩点花的。</p>
<p>本站的主题参考 <a href="https://blog.spencerwoo.com">@SpencerWooo</a> <a href="https://blog.jalenchuh.cn">@JalenChuh</a> 仓库修改，基于 Gridsome 主题 <a href="https://github.com/gridsome/gridsome-starter-blog">gridsome-starter-blog</a> 。中国境内部署于阿里云 OSS，境外部署于 Vercel。</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[从零开始的追番生活]]></title>
            <link>https://blog.monsterx.cn/tech/auto-download-bangumi-with-aria2/</link>
            <guid>https://blog.monsterx.cn/tech/auto-download-bangumi-with-aria2/</guid>
            <pubDate>Tue, 28 Jul 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>最近觉得为了偶尔看看电影动漫而续费腾讯视频会员太吃亏了，一个月四集的《斗罗大陆》水得不行啊喂！哔哩哔哩大会员也是如此，有的时候我在这头，想看的番剧在那头，每次都要科学上网才能解锁，属实费劲。</p>
<p>想了想自己闲置的服务器和最近开通的 Microsoft 365 E5 开发者订阅，我决定自己动手，部署一套更省钱的追番流程。最初是这样一套笨笨的追番流程：「bangumi.moe 等种子站找资源 -&gt; 服务器 Aria2 下载 -&gt; Rclone + Aria2 联动将内容转移到云盘 -&gt; 云盘网页下载」。但是这样一来科学上网工具的流量开销比较大，而且也完全称不上自动。后来我发现 Windows 系统打开 OneDrive 文件夹同步就可以免去手动登录网页下载，于是我从之前的 Google Drive 迁移到 OneDrive，这样一来流程的后两步就合并了。如何让前两步合并呢?一番搜索之后我找到了 Flexget 这个 Python 编写的工具，众多插件使得 Flexget 在 RSS 订阅下载上大放异彩。本文便记录这一部署过程。</p>
<h2 id="rclone">Rclone</h2>
<p>Rclone 用于网盘挂载，从 <a href="https://rclone.org/downloads/">官方</a> 下载安装，按照命令行提示输入后得到配置文件 rclone.conf（后续使用），路径一般为 <code>~/.config/rclone/rclone.conf</code> 。</p>
<p>注意使用自己的 Secret ID &amp; Key，据说能极大的提高文件传输速率。公用的 API 想想就知道肯定比不过自建。参考文档 <a href="https://rclone.org/drive/#making-your-own-client-id">GoogleDrive: Making your own client_id</a> 和 <a href="https://rclone.org/onedrive/#getting-your-own-client-id-and-key">OneDrive: Getting your own Client ID and Key</a> 创建即可。</p>
<p>Rclone 挂载 OneDrive 时需要在运行图形界面的系统上完成。Linux 服务器由于一般不带图形界面，所以需要配合本地机器：在 Windows 中下载 Rclone 相应版本文件，Power Shell 进入解压后的文件夹中键入下面命令后复制 <code>Paste the following into your remote machine ---&gt;</code> 和 <code>&lt;---End paste</code> 之间的 <code>SECRET_TOKEN</code> 到远程服务器命令行中。</p>
<pre><code class="language-shell">.\rclone authorize &quot;onedrive&quot; &quot;Client_ID&quot; &quot;Client_secret&quot;</code></pre>
<p>OneDrive 更详细挂载过程可参考文章《<a href="https://p3terx.com/archives/rclone-connect-onedrive-with-selfbuilt-api.html">Rclone 进阶使用教程 - 自建私有 API 挂载 OneDrive - P3TERX</a>》。<strong>后面均使用 OneDrive 部署</strong></p>
<h2 id="aria2">Aria2</h2>
<p>Aria2 是一个强大的下载工具，这里使用 Docker 部署 Aria2 后端服务和 AriaNG 前端页面。参考文章《<a href="https://p3terx.com/archives/docker-aria2-pro.html">Aria2 Pro - 更好用的 Aria2 Docker 容器镜像 - P3TERX</a>》。</p>
<pre><code class="language-bash"># 建立 Docker 映射文件夹
mkdir /data /data/ariapro /data/ariapro/config /data/ariapro/downloads

# 复制 Rclone 配置文件
cp ~/.config/rclone/rclone.conf /data/ariapro/config/rclone.conf

# 部署 p3terx/aria2-pro 镜像
# 修改 &lt;TOKEN&gt; 为自定字符串
# 若支持 IPv6 则开启 IPV6_MODE=enable 否则需要关闭
docker run -d \
  --name ariapro \
  --restart unless-stopped \
  --log-opt max-size=1m \
  --network host \
  -e PUID=$UID \
  -e PGID=$GID \
  -e RPC_SECRET=&lt;TOKEN&gt; \
  -e RPC_PORT=6800 \
  -e LISTEN_PORT=6888 \
  -e IPV6_MODE=enable \
  -e SPECIAL_MODE=rclone \
  -v /data/ariapro/config:/config \
  -v /data/ariapro/downloads:/downloads \
  p3terx/aria2-pro

# 部署 p3terx/ariang 镜像
docker run -d \
  --name ariang \
  --restart unless-stopped \
  --log-opt max-size=1m \
  -p 6880:6880 \
  p3terx/ariang

# 配置 rclone 自动上传
# 根据实际修改网盘名称 drive-name 和网盘路径 drive-dir
nano /data/ariapro/config/script.conf
# 修改下载完成后执行的命令 on-download-complete 为 /root/.aria2c/upload.sh
nano /data/ariapro/config/aria2.conf

# 重启 Aria2 容器
docker restart ariapro</code></pre>
<h2 id="nginx">Nginx</h2>
<p>由于使用 IP 登录不太方便，所以继续部署 Nginx 服务反向代理 RPC 端口、绑定自己的域名。简便起见，直接使用 Ubuntu 仓库中的 nginx 包。如果服务器中已安装 Nginx，则直接新建配置文件。</p>
<pre><code class="language-bash">apt install -y nginx</code></pre>
<p>安装好后 Nginx 配置文件位于 <code>/etc/nginx</code>，于 <code>/etc/nginx/conf.d</code> 文件夹下新建 <code>.conf</code> 文件。</p>
<details><summary><strong>Nginx 配置文件</strong></summary><br />


<pre><code class="language-conf">server {
  listen [::]:80;                       # 若支持 IPv6 则启用
  listen 80;
  listen [::]:443 ssl http2;            # 若支持 IPv6 则启用
  listen 443 ssl http2;
  ssl_certificate /path/to/.crt;        # .crt 证书文件路径
  ssl_certificate_key /path/to/.key;    # .key 证书文件路径
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
  ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;
  ssl_prefer_server_ciphers on;
  ssl_session_timeout 10m;
  ssl_session_cache builtin:1000 shared:SSL:10m;
  ssl_buffer_size 1400;
  add_header Strict-Transport-Security max-age=15768000;
  server_name www.example.com;          # 域名
  access_log off;
  if ($ssl_protocol = &quot;&quot;) { return 301 https://$host$request_uri; }

  location / {
    proxy_redirect off;
    proxy_pass http://localhost:6880;     # 修改为 ariang 端口
    proxy_set_header  Host                $http_host;
    proxy_set_header  X-Real-IP           $remote_addr;
    proxy_set_header  X-Forwarded-Ssl     on;
    proxy_set_header  X-Forwarded-For     $proxy_add_x_forwarded_for;
    proxy_set_header  X-Forwarded-Proto   $scheme;
    proxy_set_header  X-Frame-Options     SAMEORIGIN;
    client_max_body_size        100m;
    client_body_buffer_size     128k;
    proxy_buffer_size           4k;
    proxy_buffers               4 32k;
    proxy_busy_buffers_size     64k;
    proxy_temp_file_write_size  64k;
  }
  location ^~ /jsonrpc {
    proxy_http_version 1.1;
    add_header Front-End-Https on;
    proxy_set_header Connection &quot;&quot;;
    proxy_set_header Host $http_host;
    proxy_set_header X-NginX-Proxy true;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    # 修改为 p3terx/aria2-pro 容器 RPC_PORT
    proxy_pass http://localhost:6800/jsonrpc;
    proxy_pass_header X-Transmission-Session-Id;
  }
  # 多个 aria2 后端示例
  # location ^~ /googlejsonrpc {                # 修改
  #   proxy_http_version 1.1;
  #   add_header Front-End-Https on;
  #   proxy_set_header Connection &quot;&quot;;
  #   proxy_set_header Host $http_host;
  #   proxy_set_header X-NginX-Proxy true;
  #   proxy_set_header X-Real-IP $remote_addr;
  #   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  #   proxy_pass http://localhost:6802/jsonrpc; # 修改
  #   proxy_pass_header X-Transmission-Session-Id;
  # }
}</code></pre>
</details><br />


<p>修改上方例子中的域名、端口即可。多个 Aria2 RPC 端口时可以参考注释掉的部分。最后重启 Nginx。</p>
<pre><code class="language-bash">service nginx restart
# nginx -s reload</code></pre>
<h2 id="rss">RSS</h2>
<p>部署 flexget 之前当然是先找支持 RSS 订阅的站点！目前我个人觉得萌番组的体验还不错！<a href="https://bangumi.moe">萌番组官网</a> / <a href="https://bangumi.moe/lite">萌番组 Lite 版官网</a> / <a href="https://bgm.ptr.moe">萌番组 Material Design 版</a>。点击搜索图标添加 Tags 搜索后 RSS 图标链接地址即为可用订阅地址，切换标题搜索同理。</p>
<p>比如 添加标签 <code>Lilith-Raws</code> <code>租借女友</code> <code>1080p</code> 和 搜索标题 “Lilith 賢者時間 1080p” 分别可以得到这两种 RSS 订阅地址：</p>
<pre><code>https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5efffb4f3d656e43622cacc9
https://bangumi.moe/rss/search/Lilith%20%E8%B3%A2%E8%80%85%E6%99%82%E9%96%93%201080p</code></pre><p>除了 bangumi.moe 之外还有很多平台，部分资源相同，罗列一些包括但不限于二次元的资源站：</p>
<ul>
<li>BT RSS 订阅<ul>
<li><a href="https://share.dmhy.org">動漫花園資源網</a> 动漫、日剧、游戏、特摄等</li>
<li><a href="https://acg.rip">ACG.RIP</a> 动画、日剧、综艺、音乐等</li>
<li><a href="https://bt.xfsub.org">旋风动漫分享站</a> 漫画！</li>
<li><a href="https://nyaa.si">Nyaa</a> 侧重于东亚（中日韩）多媒体资源，被日本政府确定为主要的数字盗版网站</li>
<li><a href="https://yts.mx">YIFY</a> 以 BitTorrent 分发大量免费下载的电影而闻名，国内很多电影资源源头</li>
<li><a href="https://eztv.io">EZTV</a> 国外电视节目等，“TV Torrents Online Series Download”</li>
<li><a href="https://thepiratebay10.org/">The Pirate Bay 10</a> 据称是“the galaxy&#39;s most resilient BitTorrent site”</li>
<li><a href="http://f.cili001.com/home.html">MAG 磁力站</a> 侧重影视剧集，可以搜人人影视专用链接</li>
</ul>
</li>
<li>字幕<ul>
<li><a href="https://bbs.vcb-s.com/forum-37-1.html">VCB-S 分享论坛</a> ACG 字幕分享</li>
<li><a href="https://subhd.tv/">SubHD.tv</a> 资源+字幕站，找字幕体验非常好</li>
<li><a href="http://www.zmtiantang.cc">字幕天堂</a></li>
</ul>
</li>
<li>漫画<ul>
<li><a href="http://www.animetox.com">Animex 动漫社</a> 最近找进击的巨人漫画发现的</li>
<li><a href="http://mangabz.com">Māngabz</a> 在线漫画阅读</li>
<li><a href="https://www.dmzj.com">动漫之家</a></li>
<li><a href="https://www.omyschool.com">木马漫画</a></li>
</ul>
</li>
</ul>
<h2 id="flexget">Flexget</h2>
<p>以上部分搭建了基础的下载环境，接下来利用 Flexget 实现 aria2 的 RSS 订阅下载。</p>
<blockquote>
<p>FlexGet is a multipurpose automation tool for all of your media <br />
Support for torrents, nzbs, podcasts, comics, TV, movies, RSS, HTML, CSV, and more. <br />
<a href="https://flexget.com/">Official website</a></p>
</blockquote>
<p>由于是 Python 编写，需要先安装 python3 pip3 包。</p>
<pre><code class="language-bash">apt install python3 python3-pip
pip3 install --upgrade pip setuptools
pip3 install flexget</code></pre>
<p>安装完成后新建 Flexget 配置文件夹并编写 Flexget 配置文件。</p>
<pre><code class="language-bash">mkdir -p ~/.config/flexget
nano ~/.config/flexget/config.yml</code></pre>
<details><summary><strong>Flexget 配置文件</strong></summary><br />


<pre><code class="language-yaml">schedules:
  - tasks: &quot;*&quot;
    schedule:
      hour: &quot;*/2&quot;

tasks:
  KanojoOkarishimasu:
    rss: https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5efffb4f3d656e43622cacc9
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /租借女友/
  YahariOrenoSeishunLovecomewaMachigatteIruKan:
    rss: https://bangumi.moe/rss/tags/5d8b3245306f1a0007bd7aca+548ee2ce4ab7379536f56358+5e822875657e22f4195cc78c
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /我的青春恋爱物语果然有问题.完/
  DouLuoDaLu:
    rss: https://bangumi.moe/rss/search/GM-Team%20%E6%96%97%E7%BD%97%E5%A4%A7%E9%99%86%201080p
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /斗罗大陆/
  Japan4KAnimeYTSMX:
    rss: https://yts.mx/rss/0/2160p/animation/0/ja
    accept_all: yes
    aria2:
      server: localhost
      port: 6800
      secret: &lt;TOKEN&gt;
      path: /YTS.MX.Japan4KAnime/</code></pre>
</details><br />


<p>注意修改 Aria2 后端端口和 Secret。保存后手动运行测试一次，选一种模式设置定时任务，查看状态。</p>
<pre><code class="language-bash">flexget --test execute

flexget status

# Daemon 模式定时任务
#  -d                     后台运行
#  --autoreload-config    执行前重新载入配置文件
@reboot /usr/local/bin/flexget daemon start -d --autoreload-config

# Crontab 模式定时任务
# 删掉前面配置文件中的 scheduler 块配置
# 使用偏好的编辑器进入，添加一行
crontab -e
*/30 * * * * /usr/local/bin/flexget --cron execute</code></pre>
<p>关于定时任务，上方示例中开头 L1-4 的配置使用了 scheduler 插件，只有在 Daemon 模式下才可用。使用 crontab 定时任务不需要该配置。</p>
<h2 id="local">Local</h2>
<p>最后一步，在本地登录 OneDrive 账号设置同步文件夹。右键将本地文件夹标记为“始终在此设备上保留”即可，当云端存入新的文件时本地就会自动下载同步。删除本地文件夹时，默认会将 OneDrive 云端文件一同删除，只删除本地需要右键选择“释放空间”。</p>
<p>白嫖的开发者订阅 OneDrive 服务器位于境外，从服务器 Rclone 上传文件速度很好，但是有人说本地下载速度太慢，这无法避免。如果使用世纪互联版 OneDrive 本地下载速度肯定会好很多，但服务器上传想必会慢些，自行权衡吧。我使用几周以来尚且满意，睡一觉起来想要看的东西就会自己出现在那里，宅の生活质量提升了，人也变得精神了呢！</p>
<h2 id="end">End</h2>
<p>关于部署上面流程的服务器强烈推荐使用国外的，国内的服务器网络带宽、Docker 部署、BT 下载环境一言难尽。我用的是 Digital Ocean 新加坡服务器，体验良好。如果就看看新番、一集一集下硬盘需求不是很高，20-40GB 应该就可以了，要拿来正儿八经下东西硬盘还得越大越好的，这几天下的紫罗兰 4K 版全集就有 43GB 了。本想着部署“省钱”的追番流程，结果下载服务器一个月就花了几十刀，害，钱还是得花！</p>
<p>另外安利一个微软收购的文件转移工具：<a href="https://mover.io/">Mover</a> 安全、强大、快速的文件转移工具，Microsoft 365 用户福音，可以实现 Box，Dropbox，Google，Amazon，Office 365（原 Microsoft 365） 向 Microsoft 365 转移文件，并且支持定时任务！</p>
<ul>
<li>现成的 OneDrive 文件：<a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/EkM5OfD1nrZBr_214_JmLtgBNz05mQMNqIEFsZOb9FIMBg?e=EM2tX5">Anime</a> / <a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/EozDcDrM7edEpnZmeL1dDQABZg0xhZNUvnj7IvBlHKM6YA?e=M944ih">Movies</a> / <a href="https://monstx-my.sharepoint.com/:f:/g/personal/storage_tingle_dev/ErcXo0q92thGqrbkpzurmI8BOXwGMJgP0AiwB5lZa_cvuw?e=SM2cWU">Series</a></li>
<li>部分境外服务器可能禁止 BT 服务，选购前请仔细阅读用户条例</li>
<li>有条件的话下载完毕后请做种一段时间</li>
</ul>
<p>&nbsp;</p>
<center><span style="font-size:30px">微软赛高！</span></center>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[照葫芦画瓢 · 编写 Actions 打卡工作流]]></title>
            <link>https://blog.monsterx.cn/tech/modified-git-hub-actions-4-heu-checkin/</link>
            <guid>https://blog.monsterx.cn/tech/modified-git-hub-actions-4-heu-checkin/</guid>
            <pubDate>Tue, 30 Jun 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>昨天逛博客看到了使用 GitHub Actions 定时调用 Microsoft 365 E5 API 以帮助续订的文章，我转念一想这是不是也可以用来跑定时任务打卡呢？说干就干我开了一个小的坑：用 GitHub Actions 跑之前写的 Python 打卡脚本。无意薅羊毛，只是希望通过一点学习将自己的想法实现。</p>
<h2 id="照葫芦环节">照葫芦环节</h2>
<p>参考项目 <a href="https://github.com/wangziyingwen/AutoApiSecret">@wangziyingwen/AutoApiSecret</a> 的 <a href="https://github.com/wangziyingwen/AutoApiSecret/blob/master/.github/workflows/autoapi.yml">工作流</a>，搞懂了这一流程：</p>
<ol>
<li>将私密信息存于仓库 Secrets，以 <code>name=value</code> 的赋值语句格式定义</li>
<li>将 Secrets 内容写入脚本复制来的临时文件</li>
<li>执行填入了 Serects 的临时文件</li>
<li>删除所有临时文件并提交历史记录</li>
</ol>
<p>“定时”这一特性是 GitHub Actions 提供的，在触发条件中定义 <code>on.schedule.cron</code> 即可！呐噜吼多！将 Secrets 写入文件是通过 Linux 命令 <code>sed</code> 实现的，比如使用 <code>sed -i &#39;10 r tmp.txt&#39; tmp.py</code> 可以将 <code>tmp.txt</code> 的内容写入了 <code>tmp.py</code> 的指定行 <code>10</code> 的下一行。对 Linux 命令的认知水平停留在 rm -rf 的我大吃一惊，呀，又学到了新知识！</p>
<h2 id="画瓢环节">画瓢环节</h2>
<p>此刻，白嫖是第一生产力。了解了这样的流程部署自己的自动打卡（让 GitHub 定时执行 <code>python checkin.py</code>）就不是什么难事了。</p>
<details><summary><strong>照葫芦画瓢 python.yml 第一版</strong></summary><br />


<pre><code class="language-yaml">name: Auto Checkin

on: 
  release:
    types: [published]
  # Coordinated Universal Time (UTC)
  schedule:
    - cron: &#39;0 0 * * *&#39;           # 定时任务实现方式
  watch:
    types: [started]

jobs:
  build:
    runs-on: ubuntu-latest
    if: github.event.repository.owner.id == github.event.sender.id  # 仅自己点的 star 触发
    steps:
      - name: Checkout
        uses: actions/checkout@master

      - name: Python Setup
        uses: actions/setup-python@v1
        with:
          python-version: 3.8

      - name: Pip Cache             # 按照官方仓库 @actions/cache 添加
        uses: actions/cache@v2
        with:
          path: ~/.cache/pip        # Ubuntu 的缓存位置，不同系统不同位置需要修改
          key: ${{ runner.os }}-pip-${{ hashFiles(&#39;**/requirements.txt&#39;) }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Addons Install        # 安装脚本必须组件 lxml requests
        run: pip install lxml requests

      - name: Secrets Get           # 获取 Secrets
        env: 
          SECRET_ID: ${{ secrets.SECRET_ID }}
          SECRET_PASS: ${{ secrets.SECRET_PASS }}
          SECRET_BOUND: ${{ secrets.SECRET_BOUND }}
          SECRET_DATA: ${{ secrets.SECRET_DATA }}
        # 先复制一个临时文件，然后写入 Secrets 到文本，再将其写入临时脚本文件指定行
        run: | 
          cp checkin.py action.py
          echo $SECRET_ID &gt; action-id.txt
          echo $SECRET_PASS &gt; action-pass.txt
          echo $SECRET_BOUND &gt; action-bound.txt
          echo $SECRET_DATA &gt; action-data.txt
          sed -i &#39;19 r action-id.txt&#39; action.py
          sed -i &#39;20 r action-pass.txt&#39; action.py
          sed -i &#39;21 r action-bound.txt&#39; action.py
          sed -i &#39;22 r action-data.txt&#39; action.py

      - name: Checkin Action
        env:
          TZ: Asia/Shanghai         # 设定时区为北京时间
        # 工作流过程中新建 log 文件夹存放待会发布到另外一个分支的内容
        run: | 
          mkdir log
          echo `date +&quot;%Y-%m-%d %H:%M:%S %A&quot;` &gt;&gt; log/time.log
          python action.py &gt;&gt; log/time.log

      - name: Secrets Delete        # 删除临时文件
        run: rm -f action*

      - name: Deploy Log            # 发布 log 文件夹下的记录文件到 log 分支
        uses: docker://peaceiris/gh-pages:v2
        env:
          TZ: Asia/Shanghai
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PUBLISH_BRANCH: log
          PUBLISH_DIR: ./log
        with:
          emptyCommits: false</code></pre>
</details><br />


<p>第一版的工作流程看起来有点臃肿，不过管他呢，能用。</p>
<h2 id="润色">润色</h2>
<p>写完第一份工作流文件之后，我开心地将文件提交到了 GitHub 仓库，又煞有介事地写了份文档。但是坐下来反复看自己的代码之后，我越发觉得这过于粗糙。在博客的文章收到了大佬的指导，于是我有了新的思路并开始不断地给自己的代码“润色”。</p>
<h3 id="round-1">Round 1</h3>
<p>简单地实现定时任务似乎并不值得记录，于是我顺便给这个工作流引入了 pip 模块缓存、发布日志文件到分支这两个小功能，算是补上了之前折腾工作流学到的。</p>
<ul>
<li><p><strong>pip 模块缓存</strong></p>
<p>这是从苏卡大大在 Cloudflare Workers Sites 部署 Hexo 博客的 <a href="https://blog.skk.moe/post/deploy-blog-to-cf-workers-site">文章</a> 中学到的。Node.js 项目构建时需要的依赖挺多，没有缓存的话每次 GitHub Action 得跑很长分钟，于是他给出了缓存 node_modules 的办法： <code>uses: actions/cache@v2</code> ，通过检查缓存特征 Key 是否存在，比如 Node.js 就检测是否存在 package-lock.json 文件，进而处理缓存。</p>
<p>GitHub Actions 使用这一特性其实很简单，只要按照 <a href="https://github.com/actions/cache">@actions/cache</a> 中需要缓存的类型确定好监测的特定路径和文件，编写类似上方 L26-31 的步骤在安装依赖前即可。之前尝试是能将用于构建并发布站点的 2 mins 工作流优化到 1 min 多，提升还是蛮大的。</p>
<p>在这个项目中缓存 pip 模块需要做的就是照葫芦画瓢检查 <code>~/.cache/pip</code> 目录下 requirements.txt 文件。</p>
</li>
<li><p><strong>发布 log 记录文件到分支</strong></p>
<p>这是从 Typecho-Theme-VOID 二次开发过程中学到的。它的 Actions 将编译好的文件存放在 build 文件夹然后发布到 nightly 分支。仅需在 workflows 中给 <code>uses: docker://peaceiris/gh-pages:v2</code> 添加两个环境变量 <code>PUBLISH_BRANCH</code> 和 <code>PUBLISH_DIR</code> 即可，v3 版本这一配置从 <code>env</code> 改为了 <code>with</code> 字段，具体可以看 <a href="https://github.com/peaceiris/actions-gh-pages">@peaceiris/actions-gh-pages</a>。</p>
</li>
<li><p><strong>邮件</strong></p>
<p>启用 GitHub Actions 后我将 Python 中的 SMTP 配置删除了，这原本是用来在服务器部署时完成任务后发送提醒的。我想只要开启 GitHub 工作流的运行提醒就好啦，后来意识到虽然 GitHub Actions 自身有邮件提醒，但它提醒的是工作流执行状况，并不能等价于打卡脚本的执行状态。这一点还有待优化。毕竟配置起来如果像上面一样一条一条添加 Secrets 的话就太繁琐了。</p>
</li>
</ul>
<h3 id="round-2">Round 2</h3>
<p>也许看官早就想说了：为什么引用 Secrets 而已，又是设置环境变量、又是将环境变量 <code>echo</code> 到 <code>.txt</code> 文件、又是将 <code>.txt</code> <code>sed</code> 写入 <code>.py</code> 的，不能简单点吗？确实，在朋友 <a href="https://xyenon.bid">XYenon</a> 的指导下我得知 Python 可以通过 <code>os.environ</code> 读取环境变量，所以简单的办法来了，将 Python 脚本中原来的赋值改写成下面的格式直接读环境变量</p>
<pre><code class="language-python">import os

myid = os.environ [&#39;SECRET_ID&#39;]</code></pre>
<p>直接读入环境变量 <code>SECRET_ID</code> 的值并赋给 <code>myid</code> 。如此一来，上面 Secrets Get、Checkin Action、Secrets Delete 三步合并为一步：</p>
<pre><code class="language-yaml">- name: Action Execute
  env:
    TZ: Asia/Shanghai
    SECRET_ID: ${{ secrets.SECRET_ID }}
    SECRET_PASS: ${{ secrets.SECRET_PASS }}
    SECRET_BOUND: ${{ secrets.SECRET_BOUND }}
    SECRET_DATA: ${{ secrets.SECRET_DATA }}
  run: python checkin.py | tee -a checkin-python.log</code></pre>
<p>心情顿时舒畅了不少！</p>
<h3 id="round-3">Round 3</h3>
<p>上次那篇关于调试 Python 打卡的 <a href="https://blog.monsterx.cn/code/HEU-Auto-Checkin-COVID19.html">文章</a> 下 <a href="https://xyenon.bid">XYenon</a> 给出了仅需用户名和密码的 Ruby 版本 <a href="https://gist.github.com/XYenon/79317d63e7f769e5bdff5b595d709b65">代码</a>。</p>
<p>代码仅 60 行，第一次看完我觉得很赞，看起来只要脚本代替人执行「确认信息 -&gt; 提交表单」两步就完事了。现有的 Python 打卡每次都将事先定义的表单数据提交一遍，不考虑打卡系统中表单在服务器的缓存。如果表单数据在服务器上一直都有缓存，那部署这个 Ruby 版本我觉得似乎会更好，毕竟仓库里可以少写两个 Secrets。</p>
<blockquote>
<p>与 Python 类似，Ruby 也可以在代码中使用 <code>ENV[&#39;SECRET_ID&#39;]</code> 这样的语句直接获取环境变量。</p>
</blockquote>
<p>实际调试的时候，我发现这看起来简单的代码部署起来也不容易…… Ruby 使用 webdrivers 库来在终端驱动一个 headless Chrome 浏览器，然后执行动作。抛开因为不熟悉 Ruby + webdrivers 这套环境使我在 GitHub Actions 工作流写法上花的时间，这个脚本跑起来效率也比较低，Python 直白地提交表单整个工作流程需要 30 秒左右，而 Ruby 模拟 Chrome 操作花了三分钟多。是为了更快的 workflow 选择 Python 打卡呢？还是为了更快的部署选择 Ruby 打卡呢？</p>
<p>经过多方搜索我使用了这样的 GitHub Actions 环境跑 Ruby + Watir + webdrivers 代码，不知道有没有更好的方式，贴在这里供大家参考：</p>
<pre><code class="language-yaml">jobs:
  build:
    runs-on: ubuntu-latest
    # 运行 headless chrome 的服务
    services:
      hub:
        image: selenium/hub:3.141.59-gold
        env:
          SELENIUM_HUB_HOST: localhost
      chrome:
        image: selenium/node-chrome:3.141.59-gold
        env:
          HUB_HOST: localhost
          HUB_PORT: 9515

    if: github.event.repository.owner.id == github.event.sender.id
    steps:
      - name: Checkout
        uses: actions/checkout@master

      - name: Ruby Setup
        uses: actions/setup-ruby@v1
        with:
          ruby-version: 2.5.x

      - name: Addons Install
        run: gem install watir webdrivers

      - name: Action Execute
        env:
          TZ: Asia/Shanghai
          LANG: zh_CN.UTF-8
          SECRET_ID: ${{ secrets.SECRET_ID }}
          SECRET_PASS: ${{ secrets.SECRET_PASS }}
        run: ruby checkin.rb | tee -a checkin-ruby.log</code></pre>
<blockquote>
<p>也许 Ruby 版本的打卡程序更适合写成 JavaScript 用户脚本交给浏览器插件执行。</p>
</blockquote>
<h2 id="结语">结语</h2>
<p>GitHub <a href="https://github.com/monsterxcn/HEU-Checkin-COVID-19">@monsterxcn/HEU-Checkin-COVID-19</a></p>
<p>我原以为在 GitHub Actions 中实现定时任务要很复杂的配置，毕竟每次工作流都是相当于在一个全新的服务器上执行。现在发现原来定时任务只需要在工作流的触发事件中写入 <code>schedule</code> 即可。在查找文档时我发现这点在官方文档中有详细说明，害，都是不会看文档惹的祸。</p>
<p>榆木脑袋的我在看到别人的代码之前总是从没想过可以这样实现。比如：将私密信息以赋值语句形式写入仓库设置，执行 Actions 时将赋值语句插进文件头部继续执行。甚是高明（虽然到后面我发现这也挺笨的）。剖析了我的不足之处，浅层来看最重要的两点估计就是：</p>
<ul>
<li>我对仓库 Secrets 设置的认识是死板的，我一直将其当作 Actions 执行时传递普通变量值的纽带，仅此而已</li>
<li>不熟悉 Linux命令，虽然日常 Copy 到命令行的 Linux 命令中也有用到过 <code>sed</code> ，但我并没有积极的学习</li>
</ul>
<p>深层次的原因嘛，大概是怠惰吧！</p>
<p>GitHub Actions 妙用多多，之前关注过一个博客 <a href="https://p3terx.com/">P3TERX ZONE</a> 里写了挺多关于 GitHub Actions 的文章，有时间的话要去学习学习！</p>
]]></content:encoded>
        </item>
    </channel>
</rss>